name: Predictive maintenance Data Pipeline

on:
  push:
    branches:
      - main  

jobs:
  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install -r predictive_maintenance/requirements.txt
      - name: Upload Dataset to Hugging Face Hub
        env:
          HF_PM_TOKEN: ${{ secrets.HF_PM_TOKEN }}
        run: python predictive_maintenance/build_model/dtg.py

  data-prep:
    needs: register-dataset
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install -r predictive_maintenance/requirements.txt
      - name: Run Data Preparation
        env:
          HF_PM_TOKEN: ${{ secrets.HF_PM_TOKEN }}
        run: python predictive_maintenance/build_model/feature_processor.py

  model-training:
    needs: data-prep
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install -r predictive_maintenance/requirements.txt
      - name: Start MLflow Server
        run: |
          # Start MLflow UI in the background on the required host and port
          nohup mlflow ui --host 0.0.0.0 --port 5000 &
          sleep 5  # Wait for a moment to let the server start
      - name: Train Model
        env:
          MLFLOW_TRACKING_URI: http://0.0.0.0:5000
          HF_PM_TOKEN: ${{ secrets.HF_PM_TOKEN }}
        run: python predictive_maintenance/build_model/train.py

  deploy-hosting:
    runs-on: ubuntu-latest
    needs: [model-training, data-prep, register-dataset]
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install -r predictive_maintenance/requirements.txt
      - name: Deploy to Hugging Face Space
        env:
          HF_PM_TOKEN: ${{ secrets.HF_PM_TOKEN }}
        run: python predictive_maintenance/deployment/hosting.py
